{"metadata":{"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":9027561,"sourceType":"datasetVersion","datasetId":5440877},{"sourceId":9093524,"sourceType":"datasetVersion","datasetId":5487562},{"sourceId":9095250,"sourceType":"datasetVersion","datasetId":5488819},{"sourceId":3848,"sourceType":"modelInstanceVersion","modelInstanceId":2749,"modelId":324},{"sourceId":3849,"sourceType":"modelInstanceVersion","modelInstanceId":2750,"modelId":324}],"dockerImageVersionId":30746,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"papermill":{"default_parameters":{},"duration":17829.073559,"end_time":"2024-08-04T13:27:59.397523","environment_variables":{},"exception":true,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2024-08-04T08:30:50.323964","version":"2.5.0"},"colab":{"provenance":[],"gpuType":"T4"},"accelerator":"GPU"},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport os\nimport json\nfrom shapely.geometry import Polygon\nimport pandas as pd\nimport itertools\nimport tifffile as tiff\nfrom skimage import measure\nfrom tqdm import tqdm\nimport sys\nsys.path.append(\"..\")\nfrom segment_anything import sam_model_registry, SamAutomaticMaskGenerator, SamPredictor","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","papermill":{"duration":6.551055,"end_time":"2024-08-04T08:30:59.762584","exception":false,"start_time":"2024-08-04T08:30:53.211529","status":"completed"},"tags":[],"id":"8eb8889a","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport os\nimport json\nfrom shapely.geometry import Polygon\nfrom skimage import measure\nfrom tqdm import tqdm\nimport itertools\nimport tifffile as tiff\nimport concurrent.futures  # Ensure this import is present","metadata":{"papermill":{"duration":0.013824,"end_time":"2024-08-04T08:30:59.782409","exception":false,"start_time":"2024-08-04T08:30:59.768585","status":"completed"},"tags":[],"id":"51725b6f","execution":{"iopub.status.busy":"2024-08-10T03:54:55.784417Z","iopub.execute_input":"2024-08-10T03:54:55.785135Z","iopub.status.idle":"2024-08-10T03:54:55.793783Z","shell.execute_reply.started":"2024-08-10T03:54:55.785101Z","shell.execute_reply":"2024-08-10T03:54:55.792644Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import multiprocessing as mp\n\nmp.set_start_method('spawn', force=True)\n","metadata":{"papermill":{"duration":0.013074,"end_time":"2024-08-04T08:30:59.801098","exception":false,"start_time":"2024-08-04T08:30:59.788024","status":"completed"},"tags":[],"id":"9a75332c","execution":{"iopub.status.busy":"2024-08-10T03:54:55.800075Z","iopub.execute_input":"2024-08-10T03:54:55.800695Z","iopub.status.idle":"2024-08-10T03:54:55.805197Z","shell.execute_reply.started":"2024-08-10T03:54:55.800662Z","shell.execute_reply":"2024-08-10T03:54:55.804232Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nfrom segment_anything import sam_model_registry\n\n# Define model type and device\nmodel_type = \"vit_b\"\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n\n\n\nsam = sam_model_registry[model_type](checkpoint=\"/kaggle/input/segment-anything/pytorch/vit-b/1/model.pth\")\nsam.to(device=device)\n\nprint(f\"Model loaded on {device}\")\n","metadata":{"papermill":{"duration":5.75849,"end_time":"2024-08-04T08:31:05.565184","exception":false,"start_time":"2024-08-04T08:30:59.806694","status":"completed"},"tags":[],"id":"f772834f","outputId":"c3ce8829-1666-41d0-a3d3-edf3eab3ab7e","execution":{"iopub.status.busy":"2024-08-10T03:54:55.806397Z","iopub.execute_input":"2024-08-10T03:54:55.80672Z","iopub.status.idle":"2024-08-10T03:55:00.642481Z","shell.execute_reply.started":"2024-08-10T03:54:55.806689Z","shell.execute_reply":"2024-08-10T03:55:00.64142Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Function to extract polygons from segmentation masks\ndef extract_polygons(segmentation, num_points_threshold, min_area):\n    contours = measure.find_contours(segmentation, 0.5)\n    contours = [contour for contour in contours if len(contour) >= num_points_threshold]\n    contours = [contour for contour in contours if Polygon(contour).area >= min_area]\n    polygons = []\n    for contour in contours:\n        polygon = []\n        for point in contour:\n            polygon.append(float(point[1]))  # X coordinate\n            polygon.append(float(point[0]))  # Y coordinate\n        polygons.append(polygon)\n    return polygons","metadata":{"papermill":{"duration":0.016761,"end_time":"2024-08-04T08:31:05.588669","exception":false,"start_time":"2024-08-04T08:31:05.571908","status":"completed"},"tags":[],"id":"5b4538ba","execution":{"iopub.status.busy":"2024-08-10T03:55:00.643828Z","iopub.execute_input":"2024-08-10T03:55:00.644176Z","iopub.status.idle":"2024-08-10T03:55:00.651233Z","shell.execute_reply.started":"2024-08-10T03:55:00.644143Z","shell.execute_reply":"2024-08-10T03:55:00.650396Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Function to save results to a JSON file\ndef save_results_to_json(results, output_file):\n    with open(output_file, 'w') as f:\n        json.dump(results, f, indent=4)","metadata":{"papermill":{"duration":0.01416,"end_time":"2024-08-04T08:31:05.608925","exception":false,"start_time":"2024-08-04T08:31:05.594765","status":"completed"},"tags":[],"id":"7ae7fc6c","execution":{"iopub.status.busy":"2024-08-10T03:55:00.652551Z","iopub.execute_input":"2024-08-10T03:55:00.65293Z","iopub.status.idle":"2024-08-10T03:55:00.666049Z","shell.execute_reply.started":"2024-08-10T03:55:00.65289Z","shell.execute_reply":"2024-08-10T03:55:00.665245Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\ndef process_image(image_path, combo, num_points_threshold, min_area):\n    try:\n        image = tiff.imread(image_path)\n        band_red = image[:, :, combo[0]]\n        band_green = image[:, :, combo[1]]\n        band_blue = image[:, :, combo[2]]\n\n        rgb_image = np.dstack((band_red, band_green, band_blue))\n        image = (rgb_image - np.min(rgb_image)) / (np.max(rgb_image) - np.min(rgb_image))\n\n        image = (image * 255).astype(np.uint8)\n\n        segmentations = mask_generator.generate(np.array(image))\n\n        annotations = []\n        for segmentation in segmentations:\n            polygons = extract_polygons(segmentation['segmentation'], num_points_threshold, min_area)\n            for polygon in polygons:\n                annotations.append({\n                    \"class\": \"field\",\n                    \"segmentation\": polygon\n                })\n        return {\n            \"file_name\": os.path.basename(image_path),\n            \"annotations\": annotations\n        }\n    except Exception as e:\n        print(f\"Error processing {image_path}: {e}\")\n        return {\n            \"file_name\": os.path.basename(image_path),\n            \"annotations\": []\n        }\n","metadata":{"papermill":{"duration":0.018704,"end_time":"2024-08-04T08:31:05.633708","exception":false,"start_time":"2024-08-04T08:31:05.615004","status":"completed"},"tags":[],"id":"e1b7c601","execution":{"iopub.status.busy":"2024-08-10T03:55:00.667122Z","iopub.execute_input":"2024-08-10T03:55:00.667439Z","iopub.status.idle":"2024-08-10T03:55:00.677701Z","shell.execute_reply.started":"2024-08-10T03:55:00.66741Z","shell.execute_reply":"2024-08-10T03:55:00.676778Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport itertools\nfrom tqdm import tqdm\n\n# Define the top 5 channel combinations\ntop_combinations = [\n    (1, 3, 6),\n\n\n\n\n]\n\ndef process_images(image_dir, output_dir, num_points_threshold, min_area):\n    for combo in top_combinations:\n        results = {\"images\": []}\n\n        image_paths = [os.path.join(image_dir, filename) for filename in os.listdir(image_dir) if filename.endswith('.tif')]\n\n        for image_path in tqdm(image_paths, desc=f\"Processing combo {combo}\"):\n            result = process_image(image_path, combo, num_points_threshold, min_area)\n            results[\"images\"].append(result)\n\n        output_file = os.path.join(output_dir, f'segmentation_results_combo_{combo[0]}_{combo[1]}_{combo[2]}.json')\n        save_results_to_json(results, output_file)\n        print(f\"Results saved to {output_file}\")\n\n","metadata":{"papermill":{"duration":0.017631,"end_time":"2024-08-04T08:31:05.657389","exception":false,"start_time":"2024-08-04T08:31:05.639758","status":"completed"},"tags":[],"id":"3d374e87","execution":{"iopub.status.busy":"2024-08-10T03:55:00.678842Z","iopub.execute_input":"2024-08-10T03:55:00.679255Z","iopub.status.idle":"2024-08-10T03:55:00.689887Z","shell.execute_reply.started":"2024-08-10T03:55:00.679224Z","shell.execute_reply":"2024-08-10T03:55:00.689094Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Mask generator settings\nmask_generator = SamAutomaticMaskGenerator(\n    model=sam,\n    points_per_side=65,\n    pred_iou_thresh=0.91,\n    stability_score_thresh=0.97,\n    crop_n_layers=2,\n    crop_n_points_downscale_factor=2,\n    min_mask_region_area=120,  # Minimum area to consider a valid segmentation\n    \n\n)\n","metadata":{"papermill":{"duration":0.198774,"end_time":"2024-08-04T08:31:05.862482","exception":false,"start_time":"2024-08-04T08:31:05.663708","status":"completed"},"tags":[],"id":"e3f1557f","execution":{"iopub.status.busy":"2024-08-10T03:56:06.701859Z","iopub.execute_input":"2024-08-10T03:56:06.702192Z","iopub.status.idle":"2024-08-10T03:56:06.888827Z","shell.execute_reply.started":"2024-08-10T03:56:06.702167Z","shell.execute_reply":"2024-08-10T03:56:06.888031Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Set parameters\nimage_dir = '/kaggle/input/field-area-segmentation-3/Field_area_segmentation/train_images/images'\noutput_dir = '/kaggle/working/'\nnum_points_threshold = 50  # Minimum number of points in a contour to be considered\nmin_area = 100  # Minimum area of a polygon to be considered\n\n# Ensure the output directory exists\nos.makedirs(output_dir, exist_ok=True)\n\n# Process images and save results\nprocess_images(image_dir, output_dir, num_points_threshold, min_area)","metadata":{"papermill":{"duration":12635.308715,"end_time":"2024-08-04T12:01:41.177254","exception":false,"start_time":"2024-08-04T08:31:05.868539","status":"completed"},"tags":[],"id":"d56e10a1","outputId":"c747bd4b-4ca4-409c-af29-1a34562f5289","execution":{"iopub.status.busy":"2024-08-10T03:55:01.011749Z","iopub.status.idle":"2024-08-10T03:55:01.012115Z","shell.execute_reply.started":"2024-08-10T03:55:01.011936Z","shell.execute_reply":"2024-08-10T03:55:01.011951Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def getIOU(polygon1: Polygon, polygon2: Polygon):\n    intersection = polygon1.intersection(polygon2).area\n    union = polygon1.union(polygon2).area\n    if union == 0:\n        return 0\n    return intersection / union\n\n\ndef compute_pq(gt_polygons: list, pred_polygons: list, iou_threshold=0.5):\n    matched_instances = {}\n    gt_matched = np.zeros(len(gt_polygons))\n    pred_matched = np.zeros(len(pred_polygons))\n\n    gt_matched = np.zeros(len(gt_polygons))\n    pred_matched = np.zeros(len(pred_polygons))\n    for gt_idx, gt_polygon in enumerate(gt_polygons):\n        best_iou = iou_threshold\n        best_pred_idx = None\n        for pred_idx, pred_polygon in enumerate(pred_polygons):\n            # if gt_matched[gt_idx] == 1 or pred_matched[pred_idx] == 1:\n            #     continue\n            try:\n                iou = getIOU(gt_polygon, pred_polygon)\n            except:\n                iou = 0\n                print('Error Polygon -> iou is 0')\n\n            if iou == 0:\n                continue\n\n            if iou > best_iou:\n                best_iou = iou\n                best_pred_idx = pred_idx\n        if best_pred_idx is not None:\n            matched_instances[(gt_idx, best_pred_idx)] = best_iou\n            gt_matched[gt_idx] = 1\n            pred_matched[best_pred_idx] = 1\n\n\n    sq_sum = sum(matched_instances.values())\n    num_matches = len(matched_instances)\n    sq = sq_sum / num_matches if num_matches else 0\n    rq = num_matches / ((len(gt_polygons) + len(pred_polygons))/2.0) if (gt_polygons or pred_polygons) else 0\n    pq = sq * rq\n\n    return pq, sq, rq","metadata":{"papermill":{"duration":0.040954,"end_time":"2024-08-04T12:01:41.244995","exception":false,"start_time":"2024-08-04T12:01:41.204041","status":"completed"},"tags":[],"id":"cbd485a3","execution":{"iopub.status.busy":"2024-08-10T03:55:01.013547Z","iopub.status.idle":"2024-08-10T03:55:01.013937Z","shell.execute_reply.started":"2024-08-10T03:55:01.013724Z","shell.execute_reply":"2024-08-10T03:55:01.013761Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport json\nimport pandas as pd\nfrom shapely.geometry import Polygon\nfrom tqdm import tqdm\n\n# Load ground truth annotations\nwith open('/kaggle/input/annotaion-json/train_annotation.json') as f:\n    gts = json.load(f)\n\nscores, files = [], []\n\n# Iterate through files in the directory\nfor k in os.listdir('/kaggle/working/'):\n    file_path = os.path.join('/kaggle/working/', k)\n\n    # Check if the item is a file\n    if os.path.isfile(file_path) and file_path.endswith('.json'):\n        with open(file_path) as f:\n            submits_json = json.load(f)\n\n        for i, _image_pred in tqdm(enumerate(submits_json['images'])):\n            fname = _image_pred['file_name']\n            annos_pred = _image_pred['annotations']\n            print(fname)\n\n            # Find matching ground truth\n            fname_gt = None\n            _image_gt = next((img for img in gts['images'] if img['file_name'] == fname), None)\n            if _image_gt is None:\n                print(f'No ground truth found for file: {fname}')\n                continue\n\n            fname_gt = _image_gt['file_name']\n            annos_gt = _image_gt['annotations']\n\n            print(f'File:{fname} - {fname_gt} Num GT: {len(annos_gt)}, Num Pred: {len(annos_pred)}')\n\n            polygons_gt, polygons_pred = [], []\n            for anno in annos_gt:\n                _polys = [(x, y) for x, y in zip(anno['segmentation'][::2], anno['segmentation'][1::2])]\n                polygons_gt.append(Polygon(_polys))\n\n            for anno in annos_pred:\n                _polys = [(x, y) for x, y in zip(anno['segmentation'][::2], anno['segmentation'][1::2])]\n                polygons_pred.append(Polygon(_polys))\n\n            pq, sq, rq = compute_pq(polygons_gt, polygons_pred)\n            print(f'File:{fname} PQ: {pq:.4f}, SQ: {sq:.4f}, RQ: {rq:.4f} Num: {len(polygons_gt)}')\n\n            scores.append([pq, sq, rq])\n            files.append(fname)\n\n        df = pd.DataFrame(scores, columns=['PQ', 'SQ', 'RQ'], index=files)\n        df['file'] = files\n\n        mean_pq = df['PQ'].mean()\n        print(f'Mean PQ: {mean_pq:.4f}')\n        df.to_csv(f'exp_{k}.csv')\n","metadata":{"papermill":{"duration":2679.307672,"end_time":"2024-08-04T12:46:20.578985","exception":false,"start_time":"2024-08-04T12:01:41.271313","status":"completed"},"tags":[],"id":"ce4cac9e","outputId":"2918327c-bd07-4fe4-a52b-ac0753827de8","execution":{"iopub.status.busy":"2024-08-10T03:55:01.015753Z","iopub.status.idle":"2024-08-10T03:55:01.01624Z","shell.execute_reply.started":"2024-08-10T03:55:01.015987Z","shell.execute_reply":"2024-08-10T03:55:01.016008Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Folder containing the CSV files\nfolder_path = '/kaggle/working/'\n\n# Initialize lists to store results\ncombos = []\nmean_pqs = []\nmean_sqs = []\nmean_rqs = []\n\n# Process each file in the folder\nfor file_name in os.listdir(folder_path)[3:]:\n    if file_name.endswith('.csv'):\n        # Extract combo from file name\n        combo = '(' + file_name.split('_')[-3] + '_' + file_name.split('_')[-2] + '_' + file_name.split('_')[-1].replace('.json.csv', '')+ ')'\n        combo = combo.replace(\"_\", \" \")\n\n        # Read the CSV file\n        file_path = os.path.join(folder_path, file_name)\n        df = pd.read_csv(file_path)\n\n        # Calculate means\n        mean_pq = df['PQ'].mean()\n        mean_sq = df['SQ'].mean()\n        mean_rq = df['RQ'].mean()\n\n        # Append results to lists\n        combos.append(combo)\n        mean_pqs.append(mean_pq)\n        mean_sqs.append(mean_sq)\n        mean_rqs.append(mean_rq)\n\n# Create a new DataFrame with the results\nresult_df = pd.DataFrame({\n    'Channels': combos,\n    'mean_pq': mean_pqs,\n    'mean_sq': mean_sqs,\n    'mean_rq': mean_rqs\n})\n\ndf_sorted = result_df.sort_values(by='mean_pq', ascending=False)\n\n# Select the top 20 values\ndf_sorted.head()","metadata":{"papermill":{"duration":0.143011,"end_time":"2024-08-04T12:46:20.83213","exception":false,"start_time":"2024-08-04T12:46:20.689119","status":"completed"},"tags":[],"id":"26161a55","outputId":"81357695-715b-40b8-ab36-9f1e413a0a08","execution":{"iopub.status.busy":"2024-08-10T03:55:01.017416Z","iopub.status.idle":"2024-08-10T03:55:01.017917Z","shell.execute_reply.started":"2024-08-10T03:55:01.017646Z","shell.execute_reply":"2024-08-10T03:55:01.017666Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def extract_polygons(segmentation, num_points_threshold, min_area):\n    contours = measure.find_contours(segmentation, 0.5)\n    contours = [contour for contour in contours if len(contour) >= num_points_threshold]\n    contours = [contour for contour in contours if Polygon(contour).area >= min_area]\n    polygons = []\n    for contour in contours:\n        polygon = []\n        for point in contour:\n            polygon.append(float(point[1]))  # X coordinate\n            polygon.append(float(point[0]))  # Y coordinate\n        polygons.append(polygon)\n    return polygons","metadata":{"papermill":{"duration":0.115677,"end_time":"2024-08-04T12:46:21.051715","exception":false,"start_time":"2024-08-04T12:46:20.936038","status":"completed"},"tags":[],"id":"46de514b","execution":{"iopub.status.busy":"2024-08-10T03:55:01.021071Z","iopub.status.idle":"2024-08-10T03:55:01.021489Z","shell.execute_reply.started":"2024-08-10T03:55:01.02128Z","shell.execute_reply":"2024-08-10T03:55:01.021296Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport numpy as np\nfrom shapely.geometry import Polygon\nfrom tqdm import tqdm\nfrom PIL import Image\n\ndef process_images(image_dir, num_points_threshold, min_area):\n    images = []\n    for filename in tqdm(os.listdir(image_dir)):\n        if filename.endswith('.tif'):\n            image_path = os.path.join(image_dir, filename)\n            image = tiff.imread(image_path)\n            band_red = image[:, :, 1]\n            band_green = image[:, :, 3]\n            band_blue = image[:, :, 6]\n\n            rgb_image = np.dstack((band_red, band_green, band_blue))\n\n            # Normalize the image to 0-255 and convert to uint8\n            image = (rgb_image - np.min(rgb_image)) / (np.max(rgb_image) - np.min(rgb_image))\n            image = (image * 255).astype(np.uint8)\n\n            # Ensure the image is in HWC format\n            if image.shape[2] == 1:  # If single channel, convert to RGB\n                image = np.stack([image] * 3, axis=-1)\n\n            segmentations = mask_generator.generate(image)  # Replace with actual function call to your segmentation model\n\n            annotations = []\n            for segmentation in segmentations:\n                polygons = extract_polygons(segmentation['segmentation'], num_points_threshold, min_area)\n                for polygon in polygons:\n                    annotations.append({\n                        \"class\": \"field\",\n                        \"segmentation\": polygon\n                    })\n            images.append({\n                \"file_name\": filename,\n                \"annotations\": annotations\n            })\n    return {\"images\": images}\n","metadata":{"papermill":{"duration":0.115161,"end_time":"2024-08-04T12:46:21.269797","exception":false,"start_time":"2024-08-04T12:46:21.154636","status":"completed"},"tags":[],"id":"dd3553f2","execution":{"iopub.status.busy":"2024-08-10T03:55:01.023719Z","iopub.status.idle":"2024-08-10T03:55:01.024222Z","shell.execute_reply.started":"2024-08-10T03:55:01.023972Z","shell.execute_reply":"2024-08-10T03:55:01.023993Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"image_dir ='/kaggle/input/field-area-segmentation-3/Field_area_segmentation/test_images/images'\n\noutput_file = 'results.json'\nNumber_of_point = 3\nsize = 10\n\n# Process images and save results\nresults = process_images(image_dir, Number_of_point, size)\nsave_results_to_json(results, output_file)\nprint(f\"Results saved to {output_file}\")","metadata":{"papermill":{"duration":2492.901159,"end_time":"2024-08-04T13:27:54.272416","exception":false,"start_time":"2024-08-04T12:46:21.371257","status":"completed"},"tags":[],"id":"ba42c6c5","outputId":"2ca3f2d4-41e0-4897-a2d1-bda9f7884419","execution":{"iopub.status.busy":"2024-08-10T03:55:01.025498Z","iopub.status.idle":"2024-08-10T03:55:01.02601Z","shell.execute_reply.started":"2024-08-10T03:55:01.025752Z","shell.execute_reply":"2024-08-10T03:55:01.025774Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"with open('/kaggle/input/annotaion-json/train_annotation.json') as f:\n    gts = json.load(f)\n\nwith open('results.json') as f:\n    val_json = json.load(f)\n\nscores, files = [], []\n\nfor i ,(_image_pred) in enumerate(val_json['images']):\n\n    fname = _image_pred['file_name']\n    annos_pred = _image_pred['annotations']\n    print(fname)\n    for j ,(_image_gt) in enumerate(gts['images']):\n        if _image_gt['file_name'] == fname:\n            fname_gt = _image_gt['file_name']\n            break\n\n    annos_gt = _image_gt['annotations']\n\n    print(f'File:{fname} - {fname_gt} Num GT: {len(annos_gt)}, Num Pred: {len(annos_pred)}')\n\n    polygons_gt, polygons_pred = [], []\n    for anno in annos_gt:\n        _polys = []\n        for ii, (x, y) in enumerate(zip(anno['segmentation'][::2], anno['segmentation'][1::2])):\n            _polys.append((x, y))\n        polygons_gt.append(Polygon(_polys))\n\n    for anno in annos_pred:\n        _polys = []\n        for ii, (x, y) in enumerate(zip(anno['segmentation'][::2], anno['segmentation'][1::2])):\n            _polys.append((x, y))\n        polygons_pred.append(Polygon(_polys))\n\n\n    pq, sq, rq = compute_pq(polygons_gt, polygons_pred)\n    print(f'File:{fname} PQ: {pq:.4f}, SQ: {sq:.4f}, RQ: {rq:.4f} Num: {len(polygons_gt)}')\n\n    scores.append([pq, sq, rq])\n    files.append(fname)\n\ndf = pd.DataFrame(scores, columns=['PQ', 'SQ', 'RQ'], index=files)\ndf['file'] = files\n\nmetrisc = df['PQ'].mean()\nprint(f'Mean PQ: {metrisc:.4f}')","metadata":{"papermill":{"duration":2.157284,"end_time":"2024-08-04T13:27:56.536084","exception":true,"start_time":"2024-08-04T13:27:54.3788","status":"failed"},"tags":[],"id":"f2f15f05","outputId":"b0c4cbd4-601e-49f1-e384-2f42e279213d","execution":{"iopub.status.busy":"2024-08-10T03:55:01.027784Z","iopub.status.idle":"2024-08-10T03:55:01.028268Z","shell.execute_reply.started":"2024-08-10T03:55:01.028016Z","shell.execute_reply":"2024-08-10T03:55:01.028036Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}